
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>4. Statistical Inference &#8212; Data-Driven Science: a Python Visual and Practical Text Book</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" href="../_static/sphinx-book-theme.2d2078699c18a0efb88233928e1cf6ed.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.be0a4a0c39cd630af62a2fcf693f3f06.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe"
        const thebe_selector_input = "pre"
        const thebe_selector_output = ".output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="shortcut icon" href="../_static/cover_favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="1. Introduction" href="../3_machine_learning/0_introduction.html" />
    <link rel="prev" title="3. Probabilities and Information Theory" href="2_probabilities_and_information_theory.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/cover_square.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Data-Driven Science: a Python Visual and Practical Text Book</h1>
  
</a>
</div>

<form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>

<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
  <ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../introduction.html">
   Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Data Representations
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../1_data_representations/0_introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../1_data_representations/1_data_visualization.html">
   2. Data Visualization
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Applied Mathematics
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="0_introduction.html">
   1. Introduction
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="1_linear_algebra.html">
   2. Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="2_probabilities_and_information_theory.html">
   3. Probabilities and Information Theory
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   4. Statistical Inference
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Machine Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../3_machine_learning/0_introduction.html">
   1. Introduction
  </a>
 </li>
</ul>
<p class="caption">
 <span class="caption-text">
  Deep Learning
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="../4_deep_learning/0_introduction.html">
   1. Introduction
  </a>
 </li>
</ul>

</nav>

 <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        <div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    
    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/2_applied_mathematics/3_statistical_inference.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
    
</div>
        <!-- Source interaction buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Connect with source repository"><i class="fab fa-github"></i></button>
    <div class="dropdown-buttons sourcebuttons">
        <a class="repository-button"
            href="https://github.com/yliess86/DataDrivenScienceBook"><button type="button" class="btn btn-secondary topbarbtn"
                data-toggle="tooltip" data-placement="left" title="Source repository"><i
                    class="fab fa-github"></i>repository</button></a>
        <a class="issues-button"
            href="https://github.com/yliess86/DataDrivenScienceBook/issues/new?title=Issue%20on%20page%20%2F2_applied_mathematics/3_statistical_inference.html&body=Your%20issue%20content%20here."><button
                type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip" data-placement="left"
                title="Open an issue"><i class="fas fa-lightbulb"></i>open issue</button></a>
        
    </div>
</div>


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/yliess86/DataDrivenScienceBook/master?urlpath=tree/2_applied_mathematics/3_statistical_inference.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#introduction">
   4.1. Introduction
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#statistical-analysis-fundamentals">
   4.2. Statistical Analysis Fundamentals
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#central-tendency">
     4.2.1. Central Tendency
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#spread">
     4.2.2. Spread
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#correlation">
     4.2.3. Correlation
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sampling-and-central-limit-theorem">
   4.3. Sampling and Central Limit Theorem
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#sample">
     4.3.1. Sample
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#central-limit-theorem">
     4.3.2. Central Limit Theorem
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#estimates">
   4.4. Estimates
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#point-estimate">
     4.4.1. Point Estimate
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#method-of-moments-mm">
       4.4.1.1. Method of Moments (MM)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#maximum-likelihood-estimation-mle">
       4.4.1.2. Maximum Likelihood Estimation (MLE)
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#maximum-a-posteriori-estimation-map">
       4.4.1.3. Maximum a Posteriori Estimation (MAP)
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#interval-estimates">
     4.4.2. Interval Estimates
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interval-estimation-of-an-expected-value">
       4.4.2.1. Interval Estimation of an Expected Value
      </a>
      <ul class="nav section-nav flex-column">
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#with-known-variance">
         4.4.2.1.1. With Known Variance
        </a>
       </li>
       <li class="toc-h5 nav-item toc-entry">
        <a class="reference internal nav-link" href="#with-unknown-variance">
         4.4.2.1.2. With Unknown Variance
        </a>
       </li>
      </ul>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#interval-estimation-of-a-proportion">
       4.4.2.2. Interval Estimation of a Proportion
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#hypothesis-testing">
   4.5. Hypothesis Testing
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#one-sample-testing">
     4.5.1. One-Sample Testing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#two-sample-testing">
     4.5.2. Two-Sample Testing
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#p-value-method">
     4.5.3. P-Value Method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#hypthesis-tests-zoo">
     4.5.4. Hypthesis Tests Zoo
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#applications">
   4.6. Applications
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#linear-vs-logistic-regression">
     4.6.1. Linear VS Logistic Regression
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naive-bayes-classification">
     4.6.2. Naive Bayes Classification
    </a>
   </li>
  </ul>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="statistical-inference">
<h1><span class="section-number">4. </span>Statistical Inference<a class="headerlink" href="#statistical-inference" title="Permalink to this headline">¶</a></h1>
<div class="section" id="introduction">
<h2><span class="section-number">4.1. </span>Introduction<a class="headerlink" href="#introduction" title="Permalink to this headline">¶</a></h2>
<p><strong>Statistical Inference</strong> uses classical statistics to observe, study, and predict patterns resulting from data analysis and probabilistic modeling. There are two main approaches to the field, either <strong>Frequentist</strong> or <strong>Bayesian</strong>. The first approach implies a fixed distribution responsible for the generation of repeated patterns in the data. We can find the best estimate of the distribution’s parameters given data samples. The last one implies that the state of the world can be updated using observed samples. The parameters of the distributions can themselves be represented using probability.</p>
<p>As an example, here is a situation explaining using the two frameworks. Imagine your phone is ringing in your house, and you want to reach it:</p>
<ul class="simple">
<li><p><strong>Frequentist</strong>: I have a mental model of my house. Given the beeping sound, I can infer the house’s area to search for my phone.</p></li>
<li><p><strong>Bayesian</strong>: On top of having a mental model of my house, I also remember from the past where I misplaced the phone. By combining my inferences using the beeps and my prior information on its location, I can identify the house area and locate my phone.</p></li>
</ul>
</div>
<div class="section" id="statistical-analysis-fundamentals">
<h2><span class="section-number">4.2. </span>Statistical Analysis Fundamentals<a class="headerlink" href="#statistical-analysis-fundamentals" title="Permalink to this headline">¶</a></h2>
<p><strong>Statistical Analysis</strong> allows us to describe patterns observed in any given dataset via <strong>Visualization</strong> or <strong>Statistical Descriptors</strong>. In statistics, we are interested in studying a given <strong>Sample</strong> from a <strong>Population</strong> of <strong>Individuals</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Statistical Descriptors are closely related to <a class="reference internal" href="2_probabilities_and_information_theory.html"><span class="doc std std-doc">Probability Descriptors</span></a>. As we will observe later in the chapter, the Observed Mean can be associated with the Expectation, the Observed Variance to the Variance, and many more.</p>
</div>
<p>Suppose we design a study on the effectiveness of some medicine for some given disease. In that case, the sample corresponds to the set of patients who participated in the study, and the population represents all the people suffering from the studied disease.</p>
<p>To give credit to a <strong>Study</strong>, in other word to <strong>Generalize</strong> its results, the sample needs to <strong>Reflect</strong> the <strong>Variation</strong> present in the entire population of interest. One way to obtain such a sample is to include <strong>Randomness</strong> in the population’s selection process.</p>
<p>Now that we have defined the context of application let us define all the fundamentals of Statistical Analysis.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The different types of visualizations that can be used to express some data series’ underlying variations have been discussed in the <a class="reference internal" href="../1_data_representations/1_data_visualization.html"><span class="doc std std-doc">Data Visualization Chapter</span></a>.</p>
</div>
<div class="section" id="central-tendency">
<h3><span class="section-number">4.2.1. </span>Central Tendency<a class="headerlink" href="#central-tendency" title="Permalink to this headline">¶</a></h3>
<p>The first type of descriptor is the <strong>Central Tendency</strong>. It expresses the central value, the typical value for a data distribution. The most common central tendency measures are the <strong>Mode</strong>, the <strong>Mean</strong>, and the <strong>Median</strong>.</p>
<p>The <strong>Mode</strong> <span class="math notranslate nohighlight">\(M_o\)</span> is the value that occurs most often in a given set of data values.</p>
<p>The <strong>Mean</strong> <span class="math notranslate nohighlight">\(\overline{x}\)</span> refers to the <strong>Arithmetic Mean</strong>:</p>
<div class="math notranslate nohighlight">
\[
\overline{x} = \frac{1}{n} \sum_{i=1}^{n} x_i
\]</div>
<p>In some cases it also refers to the <strong>Weighted Arithmetic Mean</strong>:</p>
<div class="math notranslate nohighlight">
\[
\overline{x} = \frac{1}{n} \sum_{i=1}^{n} w_i x_i
\]</div>
<p>The <strong>Median</strong> <span class="math notranslate nohighlight">\(M_e\)</span> is the variable responsible for separating the statistical distributions as two equally populated groups when organized in ascending order.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
M_e = \begin{cases}
x_{(n+1)/2} &amp; \text{if}\;n\;\text{is odd} \\
\frac{x_{n/2} + x_{n/2 + 1}}{2} &amp; \text{if}\;n\;\text{is even}
\end{cases}
\end{split}\]</div>
<p>Let us consider the following example, which compiles one exam score for each of <span class="math notranslate nohighlight">\(22\)</span> students and compute its central tendency metrics:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">pd</span><span class="o">.</span><span class="n">options</span><span class="o">.</span><span class="n">display</span><span class="o">.</span><span class="n">max_columns</span> <span class="o">=</span> <span class="mi">22</span>


<span class="n">N</span> <span class="o">=</span> <span class="mi">22</span>

<span class="c1"># Generate Data for Example</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">13</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">),</span> <span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;score&quot;</span><span class="p">])</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="n">N</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
      <th>16</th>
      <th>17</th>
      <th>18</th>
      <th>19</th>
      <th>20</th>
      <th>21</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>score</th>
      <td>14</td>
      <td>12</td>
      <td>14</td>
      <td>17</td>
      <td>12</td>
      <td>12</td>
      <td>17</td>
      <td>15</td>
      <td>11</td>
      <td>14</td>
      <td>11</td>
      <td>11</td>
      <td>13</td>
      <td>7</td>
      <td>7</td>
      <td>11</td>
      <td>9</td>
      <td>13</td>
      <td>10</td>
      <td>8</td>
      <td>17</td>
      <td>12</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mode  : </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">mode</span><span class="p">()</span><span class="o">.</span><span class="n">array</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean  : </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Median: </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">median</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Mode  : 11.00
Mean  : 12.14
Median: 12.00
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">score</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">20</span><span class="p">)</span> <span class="o">-</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">rwidth</span><span class="o">=</span><span class="mf">0.9</span><span class="p">)</span>
<span class="n">line1</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">mode</span><span class="p">()</span><span class="o">.</span><span class="n">array</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#E5AE42&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">line2</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">mean</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#F6514C&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">line3</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">median</span><span class="p">(),</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;score&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;count&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">20</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">20.5</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="p">[</span><span class="n">line1</span><span class="p">,</span> <span class="n">line2</span><span class="p">,</span> <span class="n">line3</span><span class="p">],</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Mode&quot;</span><span class="p">,</span> <span class="s2">&quot;Mean&quot;</span><span class="p">,</span> <span class="s2">&quot;Median&quot;</span><span class="p">])</span>

<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="stat-centen-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_4_0.png" src="../_images/3_statistical_inference_4_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.1 </span><span class="caption-text">Mode, Mean, and Median Visualization for a dataset containing exam’s scores of <span class="math notranslate nohighlight">\(22\)</span> students.</span><a class="headerlink" href="#stat-centen-fig" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="spread">
<h3><span class="section-number">4.2.2. </span>Spread<a class="headerlink" href="#spread" title="Permalink to this headline">¶</a></h3>
<p>The second type of descriptor is the <strong>Spread</strong> or <strong>Dispersion</strong> of a data series. It is often implied to be the spread around its mean. The most common spread measures are the <strong>Range</strong> and the <strong>Variance</strong>, thus the <strong>Standard Deviation</strong>.</p>
<p>The <strong>Range</strong> <span class="math notranslate nohighlight">\(R\)</span> of a data series is defined as the difference between its maximum and minimum values. If the values are organized in ascending order, its:</p>
<div class="math notranslate nohighlight">
\[
R = x_n - x_0
\]</div>
<p>The <strong>Variance</strong>, <span class="math notranslate nohighlight">\(s^2\)</span> for some observed data series, <span class="math notranslate nohighlight">\(\sigma^2\)</span> for some theoretical distribution, is the average sum of square difference from the mean. It explains how the data is distributed around the mean. The <strong>Standard Deviation</strong> is defined as the square root of the variance. It allows working with the same unit as the data.</p>
<div class="math notranslate nohighlight">
\[
s^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \overline{x_i})^2
\]</div>
<p>Let us consider the same example as for the central tendency and compute the range and the standard deviation of the student scores:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Range: </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">max</span><span class="p">()</span> <span class="o">-</span> <span class="n">df</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">min</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Std  : </span><span class="si">{</span><span class="n">df</span><span class="o">.</span><span class="n">score</span><span class="o">.</span><span class="n">std</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Range: 10.00
Std  : 2.93
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="correlation">
<h3><span class="section-number">4.2.3. </span>Correlation<a class="headerlink" href="#correlation" title="Permalink to this headline">¶</a></h3>
<p>The last type of descriptor is the <strong>Correlation</strong> between two variables <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>. In satistical analysis, it is often easier to interpret the correlation between two variables of the same unit. If it is not the case, it is common practice to centre and reduce the variables <span class="math notranslate nohighlight">\(x = \frac{X - \mu}{\sigma}\)</span>.</p>
<p>One of the correlation metrics is the <strong>Linear Correlation Coeficient</strong> between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> and is defined as:</p>
<div class="math notranslate nohighlight">
\[
\rho(X, Y) = \frac{Cov(X, Y)}{\sigma_X \sigma_Y},\;\;-1 \leq \rho(X, Y) \leq 1
\]</div>
<p>When <span class="math notranslate nohighlight">\(\rho(X, Y)\)</span> is closed to <span class="math notranslate nohighlight">\(-1\)</span> or <span class="math notranslate nohighlight">\(1\)</span>, it means that <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span> are linearly related, and the sign defines the direction of the linearity. If <span class="math notranslate nohighlight">\(\rho(X, Y)\)</span> is null, there is no linear dependency, no correlation between the two variables.</p>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">N</span> <span class="o">=</span> <span class="mi">100</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">12</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span><span class="p">,</span> <span class="n">ax3</span> <span class="o">=</span> <span class="p">[</span><span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>

<span class="n">XY</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">XY</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">XY</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\rho$=0&quot;</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">XY</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">XY</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\rho$=1&quot;</span><span class="p">)</span>

<span class="n">ax3</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">XY</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">],</span> <span class="o">-</span><span class="n">XY</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">])</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="sa">r</span><span class="s2">&quot;$\rho$=-1&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.40</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="stat-correl-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_10_0.png" src="../_images/3_statistical_inference_10_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.2 </span><span class="caption-text">Visualization of the linear correlation coeficient between <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(Y\)</span>.</span><a class="headerlink" href="#stat-correl-fig" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="sampling-and-central-limit-theorem">
<h2><span class="section-number">4.3. </span>Sampling and Central Limit Theorem<a class="headerlink" href="#sampling-and-central-limit-theorem" title="Permalink to this headline">¶</a></h2>
<div class="section" id="sample">
<h3><span class="section-number">4.3.1. </span>Sample<a class="headerlink" href="#sample" title="Permalink to this headline">¶</a></h3>
<p>As stated previously in the chapter, statistic analysis allows us to study some probabilistic phenomena, for example, the error in diameter of a milling machine, on a defined <strong>Sample</strong> as the statistical characteristics of an entire population cannot be measured. In statistics, a <strong>Sample</strong> has to represent a <strong>maximum</strong> of the <strong>variance</strong> present in the <strong>population</strong> it is drawn from using a <strong>known distribution</strong>.</p>
<p>A <strong>Sample</strong> can be defined as a set of <span class="math notranslate nohighlight">\(n\)</span> independant random variable <span class="math notranslate nohighlight">\((X_1,\cdots,X_n)\)</span> drawn from a same distribution. The Observations of a the sample are defined by <span class="math notranslate nohighlight">\((x_1,\cdots,x_n)\)</span>.</p>
<p>A <strong>Statistic</strong> <span class="math notranslate nohighlight">\(T\)</span> is a quantity, a measurable function, from the sample’s values.</p>
<div class="math notranslate nohighlight">
\[
T(X) = T(X_1,\cdots,X_n)
\]</div>
<p>The <strong>Empirical Mean Satistic</strong> <span class="math notranslate nohighlight">\(\overline{X}_n\)</span> is:</p>
<div class="math notranslate nohighlight">
\[
\overline{X}_n = \frac{1}{n} \sum_{i=1}^{n} X_i
\]</div>
<p>If we define <span class="math notranslate nohighlight">\(\mu\)</span> the expected value, and <span class="math notranslate nohighlight">\(\sigma^2\)</span> the variance of the random variable <span class="math notranslate nohighlight">\(X\)</span>, the <strong>Expected Value</strong> and the <strong>Variance</strong> for the statistic <span class="math notranslate nohighlight">\(\overline{X}_n\)</span> can be defined as:</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\mathbb{E}(\overline{X}_n) = \mu &amp;&amp; Var(\overline{X}_n) = \frac{\sigma^2}{n}
\end{align}
\]</div>
</div>
<div class="section" id="central-limit-theorem">
<h3><span class="section-number">4.3.2. </span>Central Limit Theorem<a class="headerlink" href="#central-limit-theorem" title="Permalink to this headline">¶</a></h3>
<p>In this section, two fundamental theorems of statistics are discussed, the <strong>Law of Large Numbers</strong> and the <strong>Central Limit Theorem</strong>. Both of them concern the <span class="math notranslate nohighlight">\(\overline{X}_n\)</span> statistic for samples of independent and identically distributed random variables.</p>
<p>The <strong>Law of Large Numbers</strong> states that for such a framework, as the sample <strong>size grows</strong>, its <strong>mean</strong> gets <strong>closer</strong> to the <strong>average</strong> of the entire <strong>population</strong>. We have been relying secretly on this theorem when dealing with Monte Carlo Simulation.</p>
<div class="math notranslate nohighlight">
\[
\overline{X}_n \rightarrow \mu \;\; \text{when} \;\; n \rightarrow +\infty
\]</div>
<p>Let us verify this fact empirically with an example. Consider a dice where <span class="math notranslate nohighlight">\(X\)</span> represents the outcome number of a throw and follows a uniform distribution.</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
P(X=x_i) = \frac{1}{6} &amp;&amp; \mathbb{E}(X) = 3.5
\end{align}
\]</div>
<p>Let us repeat the experiment <span class="math notranslate nohighlight">\(n\)</span> times and compute the statistic <span class="math notranslate nohighlight">\(\overline{X}_n\)</span>. When the sample size grows, its value should be closer to <span class="math notranslate nohighlight">\(\mu\)</span>, which is <span class="math notranslate nohighlight">\(3.5\)</span>. It is visually possible to verify that this convergence happens.</p>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">line1</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span> <span class="k">if</span> <span class="n">n</span> <span class="o">&gt;</span> <span class="mi">0</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">500</span><span class="p">)])</span>
<span class="n">line2</span><span class="p">,</span> <span class="o">*</span><span class="n">_</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">500</span><span class="p">)</span> <span class="o">*</span> <span class="mf">3.5</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#F6514C&quot;</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">handles</span><span class="o">=</span><span class="p">[</span><span class="n">line1</span><span class="p">,</span> <span class="n">line2</span><span class="p">],</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;$\overline</span><span class="si">{X_n}</span><span class="s2">$&quot;</span><span class="p">,</span> <span class="s2">&quot;$\mu$ = 3.5&quot;</span><span class="p">])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;n&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;X&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.2</span><span class="p">,</span> <span class="mf">6.2</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="stat-lln-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_14_0.png" src="../_images/3_statistical_inference_14_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.3 </span><span class="caption-text">Visualization of the Low of Large Numbers. When <span class="math notranslate nohighlight">\(n\)</span> grow, <span class="math notranslate nohighlight">\(\overline{X}_n\)</span> gets closer to <span class="math notranslate nohighlight">\(\mu\)</span>.</span><a class="headerlink" href="#stat-lln-fig" title="Permalink to this image">¶</a></p>
</div>
<p>The <strong>Central Limit Theorem</strong> States that for such a framework as the one described for this section, with expectation <span class="math notranslate nohighlight">\(\mu\)</span> and variance <span class="math notranslate nohighlight">\(\sigma^2\)</span>:</p>
<div class="math notranslate nohighlight">
\[
Z = \frac{\overline{X}_n - \mu}{\sigma / \sqrt{n}} \sim \mathcal{N}(0, 1) \;\; \text{when} \;\; n \rightarrow +\infty
\]</div>
<p>To resume, for any sample of a reasonably big size of independent random variable <span class="math notranslate nohighlight">\(X_i\)</span>, the standardized mean distribution <span class="math notranslate nohighlight">\(Z\)</span> can be simplified to a normal distribution <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span>.</p>
<p>Let us verify this fact empirically with an example. Consider the uniform distribution <span class="math notranslate nohighlight">\(U(0, 1)\)</span> and the poisson distribution <span class="math notranslate nohighlight">\(Pois(1)\)</span>. By taking samples of bigger and bigger sizes, the distribution of <span class="math notranslate nohighlight">\(\overline{X}_n\)</span> should resemble the one of a normal distribution.</p>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>

<span class="n">sizes</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">50</span><span class="p">]</span>
<span class="n">samples</span> <span class="o">=</span> <span class="mi">400</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">*</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">8</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sizes</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">),</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">X_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">X_n</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">70.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;U(0, 1)&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;n = </span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    
<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">sizes</span><span class="p">):</span>
    <span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">sizes</span><span class="p">)</span> <span class="o">+</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">X_n</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">poisson</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="p">(</span><span class="n">samples</span><span class="p">,</span> <span class="n">n</span><span class="p">))</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">X_n</span><span class="p">,</span> <span class="n">kde</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">200.5</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">(())</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span> <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Pois(1)&quot;</span><span class="p">)</span>
        
<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="stat-clt-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_18_0.png" src="../_images/3_statistical_inference_18_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.4 </span><span class="caption-text">Visualization of the Central Limit Theorem. When <span class="math notranslate nohighlight">\(n\)</span> grow, the distribution of <span class="math notranslate nohighlight">\(\overline{X}_n\)</span> gets closer to a normal distribution.</span><a class="headerlink" href="#stat-clt-fig" title="Permalink to this image">¶</a></p>
</div>
</div>
</div>
<div class="section" id="estimates">
<h2><span class="section-number">4.4. </span>Estimates<a class="headerlink" href="#estimates" title="Permalink to this headline">¶</a></h2>
<p>The goal of statistical inference is to find, to infer, some <strong>Estimate</strong> of some <strong>Parameters</strong> <span class="math notranslate nohighlight">\(\theta\)</span> governing some hypothetical distribution supposed to be responsible for the variation in the set of random variables studied <span class="math notranslate nohighlight">\(X\)</span>. The distribution is chosen appropriately using the tools of statistical analysis.</p>
<p>The idea of an <strong>Estimator</strong> is to approximate a statistical parameter. Statistical descriptors are such estimators as they approximate a statistical parameter concerning the studied population given a sample. An <strong>Estimate</strong> is the value obtained after the measurement of an estimator.</p>
<p>As it may imply in its name, <strong>approximate</strong> means that an estimate is not and <strong>never</strong> will be <strong>perfect</strong>. There is some notion of error, commonly referred to as the <strong>Margin of Error</strong>.</p>
<p>In this section, we study two different kinds of estimators, <strong>Point Estimators</strong> and <strong>Interval Estimators</strong>, and discuss approaches to find them.</p>
<div class="section" id="point-estimate">
<h3><span class="section-number">4.4.1. </span>Point Estimate<a class="headerlink" href="#point-estimate" title="Permalink to this headline">¶</a></h3>
<p><strong>Point Estimators</strong> can be created using different approaches. Among them three will be presented, the <strong>Method of Moments</strong>, the <strong>Maximum Likelihood Estimation</strong>, and the <strong>Maximum a Posteriori Estimation</strong>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Unkown Population Parameter</p></th>
<th class="text-align:center head"><p>Symbol</p></th>
<th class="text-align:left head"><p>Empirical Point Estimation</p></th>
<th class="text-align:center head"><p>Symbol</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Population mean</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\mu\)</span></p></td>
<td class="text-align:left"><p>Sample mean</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\hat{\mu}\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Population standard deviation</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\sigma^2\)</span></p></td>
<td class="text-align:left"><p>Sample variance</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\hat{\sigma}^2\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Population standard deviation</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\sigma\)</span></p></td>
<td class="text-align:left"><p>Sample standard deviation</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\hat{\sigma}\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Population proportion</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(p\)</span></p></td>
<td class="text-align:left"><p>Sample proportion</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\hat{p}\)</span></p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="method-of-moments-mm">
<h4><span class="section-number">4.4.1.1. </span>Method of Moments (MM)<a class="headerlink" href="#method-of-moments-mm" title="Permalink to this headline">¶</a></h4>
<p>Before even looking at the <strong>Method of Moments</strong>, or <strong>MM</strong> for short, we need to define a <strong>Moment</strong>. The <span class="math notranslate nohighlight">\(k\)</span>-th Moment of a given random variable <span class="math notranslate nohighlight">\(X\)</span> is expressed as:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{E}[X^k]
\]</div>
<p>We already know from now on that an approximation of the first moment of <span class="math notranslate nohighlight">\(X\)</span> is given by the sample mean:</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{n} \sum_{i=1}^{n} X_i
\]</div>
<p>Base on that we can approximate hte <span class="math notranslate nohighlight">\(k\)</span>-th Moment of <span class="math notranslate nohighlight">\(X\)</span> by:</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{n} \sum_{i=1}^{n} X_i^k
\]</div>
<p>Let us consider the following example. Considere the random sample <span class="math notranslate nohighlight">\(X_1, \dots, X_n\)</span> and try to approximate the population mean <span class="math notranslate nohighlight">\(\mu = \mathbb{E}[X]\)</span> and the variance of the popylation <span class="math notranslate nohighlight">\(\sigma^2 = \mathbb{E}[(X - \mathbb{E}[X])^2] = \mathbb{E}[X^2] - \mu^2\)</span> using the method of moments:</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\hat{\mu} = \frac{1}{n} \sum_{1}^{n} X_i &amp;&amp; \hat{\sigma}^2 = \frac{1}{n} \sum_{1}^{n} X_i^2 - \left [\ \frac{1}{n} \sum_{1}^{n} X_i \right ] ^2
\end{align}
\]</div>
<p>As you can notice, the method revolves around the sample mean and does not require any <em>PDF</em> nor <em>PMF</em> computation. One downfall of this method can be observed by looking at the second term of the variance estimator. If this term is too big, the approximation result will be negative, which is not acceptable.</p>
</div>
<div class="section" id="maximum-likelihood-estimation-mle">
<h4><span class="section-number">4.4.1.2. </span>Maximum Likelihood Estimation (MLE)<a class="headerlink" href="#maximum-likelihood-estimation-mle" title="Permalink to this headline">¶</a></h4>
<p>Another method for creating point estimators is the <strong>Maximum Likelihood</strong>. Let us remind the context we are dealing with. Consider <span class="math notranslate nohighlight">\(X_1, \dots, X_n\)</span> a random sample <em>(independent)</em> of size <span class="math notranslate nohighlight">\(n\)</span> sampled from a <em>PDF</em> or <em>PMF</em> <span class="math notranslate nohighlight">\(p(D | \theta)\)</span>. Our goal is to estimate, approximate <span class="math notranslate nohighlight">\(\theta\)</span>. In this sense, we want to find:</p>
<div class="math notranslate nohighlight">
\[
\theta_{MLE} = \underset{\theta}{argmax} \; p(D | \theta)
\]</div>
<p>This method, as its name implies, consists on <strong>maximizing</strong> a function <span class="math notranslate nohighlight">\(\mathcal{L}(\theta | X_1, \dots, X_n)\)</span> representing the <strong>Likelihood</strong> of having <span class="math notranslate nohighlight">\(\theta\)</span> given our sample. The <strong>Likelihood Function</strong> is defined as the joint <em>PMF</em> of each individual of our sample:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\mathcal{L}(\theta | X_1, \dots, X_n) &amp; = p(X_1, \dots, X_n | \theta) \\
                            &amp; = p(X_1 | \theta) \cdots \dots \cdots p(X_n | \theta) \\
                            &amp; = \prod_{i=1}^{n} p(X_i | \theta) \\
\end{align}
\end{split}\]</div>
<p>The parameter <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> that maximizes the likelihood function is called the <strong>Maximum Likelihood Estimator</strong>, or <strong>MLE</strong> for short. As a reminder, finding the maximum of some function <span class="math notranslate nohighlight">\(f\)</span> can be done by studying its derivative <span class="math notranslate nohighlight">\(f'\)</span>. In this sense we will often talk about the <strong>Log Likelihood Function</strong>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
l(\theta | X_1, \dots, X_n) &amp; = log \; \mathcal{L}(\theta | X_1, \dots, X_n) \\
                            &amp; = log \; \prod_{i=1}^{n} p(X_i | \theta) \\
                            &amp; = \sum_{i=1}^{n} log \; p(X_i | \theta)
\end{align}
\end{split}\]</div>
<p><strong>Log</strong> is a <strong>Monotonic</strong> function, it does not change the order of what it is given, and the log of a product is the sum of logs. It allows us to simplify the likelihood as a sum and thus to simplify the process of derivation.</p>
<p>Consider the following example: you are playing basket ball and after 15 independent throws, only 6 made it. Let denot <span class="math notranslate nohighlight">\(X\)</span> the number of successes. With this formulation, <span class="math notranslate nohighlight">\(x=6\)</span> and <span class="math notranslate nohighlight">\(n=15\)</span>. Now let us assume that <span class="math notranslate nohighlight">\(X \sim B(n, \theta)\)</span> and estimate <span class="math notranslate nohighlight">\(\theta\)</span> by computing its MLE.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
 l(X | \theta) &amp; = log \begin{pmatrix} n \\ X \end{pmatrix} \theta^X (1 - \theta)^{n - X} \\
 l(X | \theta) &amp; = log \begin{pmatrix} n \\ X \end{pmatrix} + Xlog(\theta) + (n - X) log(1 - \theta) \\
l'(X | \theta) &amp; = \frac{X}{\theta} - \frac{n - X}{1 - \theta}
\end{align}
\end{split}\]</div>
<p>After solving the equation <span class="math notranslate nohighlight">\(l'(X | \theta) = 0\)</span>, we obtain the following root: <span class="math notranslate nohighlight">\(\hat{\theta} = \frac{X}{n}\)</span>. If we evaluate this estimator, we obtain the Maximum Likelihood Estimate <span class="math notranslate nohighlight">\(\hat{\theta} = \frac{6}{15}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">List</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>


<span class="c1"># Replicate Trial (15 Throws, 6 Successes)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">shuffle</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
<span class="n">observations</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">6</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>
<span class="n">observations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>


<span class="c1"># Define Bernoulli Model</span>
<span class="k">class</span> <span class="nc">BernoulliModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Bernoulli Model</span>
<span class="sd">        p = theta  is unknown and initialized to 0.5</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Bernoulli PMF</span>
<span class="sd">        p^x (1 - p)^(1 - x)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">**</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">observations</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
        <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Maximum Likelihood Estimation</span>
<span class="sd">        Optimization -&gt; Gradient Ascent (find max using derivative)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">history</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
            <span class="n">loglikelihood</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="p">(</span><span class="n">observations</span><span class="p">)))</span>
            <span class="n">loglikelihood</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s2">: 𝑝̂=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">history</span>
            
            
<span class="c1"># Statistical Inference using MLE</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BernoulliModel</span><span class="p">()</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration 0: 𝑝̂=0.46
Iteration 1: 𝑝̂=0.44
Iteration 2: 𝑝̂=0.42
Iteration 3: 𝑝̂=0.41
Iteration 4: 𝑝̂=0.41
Iteration 5: 𝑝̂=0.40
Iteration 6: 𝑝̂=0.40
Iteration 7: 𝑝̂=0.40
Iteration 8: 𝑝̂=0.40
Iteration 9: 𝑝̂=0.40
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;fivethirtyeight&quot;</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>  <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span> <span class="o">=</span> <span class="p">[</span><span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>

<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">observations</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s2">&quot;Sample&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;proportion&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s2">&quot;MLE&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$\hat</span><span class="si">{p}</span><span class="s2">$&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.40</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="mle-bernoulli-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_23_0.png" src="../_images/3_statistical_inference_23_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.5 </span><span class="caption-text">Maximum Likelihood Estimate applied to the basket ball throw example. The objective is to find <span class="math notranslate nohighlight">\(p\)</span> for <span class="math notranslate nohighlight">\(B(n, p)\)</span>. Sample is represented left, and the optimization process base on the MLE right.</span><a class="headerlink" href="#mle-bernoulli-fig" title="Permalink to this image">¶</a></p>
</div>
</div>
<div class="section" id="maximum-a-posteriori-estimation-map">
<h4><span class="section-number">4.4.1.3. </span>Maximum a Posteriori Estimation (MAP)<a class="headerlink" href="#maximum-a-posteriori-estimation-map" title="Permalink to this headline">¶</a></h4>
<p>The last method presented in this section is the <strong>Maximum a Posteriori Estimation</strong> (MAP). It is similar and related to the <strong>Maximum Likelihood Estimate</strong> but considers a posterior knowledge on the parameters we want to estimate. The method can be derived from the MLE using Baye’s Theorem.</p>
<p>This technique assume the same setup of <span class="math notranslate nohighlight">\(n\)</span> random independent samples <span class="math notranslate nohighlight">\(X_1, \dots, X_n\)</span>. Our goal is to find a good estimate of some parameters <span class="math notranslate nohighlight">\(\theta\)</span> for the given dataset. Contrary to MLE, MAP consider the best estimate as beign drawn from <span class="math notranslate nohighlight">\(p(\theta|D)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\theta_{MAP} = \underset{\theta}{argmax} \; p(\theta|D)
\]</div>
<p>Instead of maximizing the likelihood function, here, we maximize a posterior distribution on the parameters.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\theta_{MAP} &amp; = \underset{\theta}{agrmax} \; p(\theta|D) \\
             &amp; = \underset{\theta}{argmax} \; \frac{p(D|\theta)p(\theta)}{p(D)} \\
             &amp; \propto \underset{\theta}{agrmax} \; p(D|\theta)p(\theta) \\
             &amp; \propto \underset{\theta}{agrmax} \; p(D|\theta)p(\theta) \\
             &amp; \propto \underset{\theta}{agrmax} \; log \; p(D|\theta) + log \; p(\theta) \\
\end{align}
\end{split}\]</div>
<p>The same process used for MLE can now be applied. It is just a matter of finding the maximum of this function by computing its derivative. It means that our best estimate <span class="math notranslate nohighlight">\(\theta_{MAP}\)</span> is the most probable <span class="math notranslate nohighlight">\(\theta\)</span> given observed data and our prior belief. It can be seen as a compromise between the likelihood and posterior belief.</p>
<p>Let us now reconsidere the example of basketball throws. This time let us consider some prior knowlege on the parameter <span class="math notranslate nohighlight">\(\theta\)</span>, the estimator of <span class="math notranslate nohighlight">\(p\)</span> in <span class="math notranslate nohighlight">\(B(n, p)\)</span>. Assuming <span class="math notranslate nohighlight">\(\theta\)</span> follows a Beta distribution <span class="math notranslate nohighlight">\(P(\theta) \sim Beta(\alpha, \beta)\)</span>:</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
P(X|\theta) = \theta^{X} (1 - \theta)^{n - X} &amp;&amp;
P(\theta) = \frac{1}{B(\alpha, \beta)} \theta^{\alpha - 1} (1 - \theta)^{\beta - 1}
\end{align}
\]</div>
<p>Using this knowledge:</p>
<div class="math notranslate nohighlight">
\[
P(\theta|X) = \frac{1}{B(X + \alpha, n - X + \beta)} \theta^{X + \alpha - 1} (1 - \theta)^{n - X + \beta - 1}
\]</div>
<p>If we look closely, we can observe that <span class="math notranslate nohighlight">\(P(\theta|X) \sim Beta(X + \alpha, n - X + \beta)\)</span>. Thus:</p>
<div class="math notranslate nohighlight">
\[
l'(\theta | X) = \frac{1}{B(X + \alpha, n - X + \beta)} (\frac{X + \alpha - 1}{\theta} - \frac{n - X + \beta - 1}{1 - \theta})
\]</div>
<p>Solving <span class="math notranslate nohighlight">\(l'(\theta | X)=0\)</span> gives us <span class="math notranslate nohighlight">\(\hat{\theta} = \frac{X + \alpha - 1}{\alpha + n + \beta - 2}\)</span>. If we choose a prior with <span class="math notranslate nohighlight">\(\alpha=0.7\)</span>, and <span class="math notranslate nohighlight">\(\beta=0.8\)</span>, <span class="math notranslate nohighlight">\(\hat{\theta} \approx 0.41\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">gamma</span>
<span class="kn">from</span> <span class="nn">torch.autograd</span> <span class="kn">import</span> <span class="n">Variable</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">List</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>


<span class="c1"># Replicate Trial (15 Throws, 6 Successes)</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">15</span>
<span class="n">shuffle</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">_</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">()</span>
<span class="n">observations</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="mi">6</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">n</span> <span class="o">-</span> <span class="mi">6</span><span class="p">),</span> <span class="n">key</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>
<span class="n">observations</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">observations</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>


<span class="c1"># Define Beta Distribution</span>
<span class="k">class</span> <span class="nc">BetaDistribution</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">alpha</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">beta</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Beta Distribution</span>
<span class="sd">        alpha and beta are chosen to be &quot;integers&quot; for simplification as</span>
<span class="sd">        G(n + 1) = n!  with G := Gamma function</span>
<span class="sd">        B(alpha, gamma) = (G(alpha)G(beta)) / G(alpha + beta)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">=</span> <span class="n">alpha</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">B_inv</span> <span class="o">=</span> <span class="n">gamma</span><span class="p">(</span><span class="n">alpha</span> <span class="o">+</span> <span class="n">beta</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">gamma</span><span class="p">(</span><span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">gamma</span><span class="p">(</span><span class="n">beta</span><span class="p">))</span>
        
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Beta PDF</span>
<span class="sd">        1/B(alpha, gamma) * x^(alpha - 1) * (1 - x)^(beta - 1)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">B_inv</span> <span class="o">*</span> <span class="p">(</span><span class="n">x</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">alpha</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span> <span class="o">*</span> <span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">beta</span> <span class="o">-</span> <span class="mi">1</span><span class="p">))</span>
    

<span class="c1"># Define Bernoulli Model</span>
<span class="k">class</span> <span class="nc">BernoulliModel</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Bernoulli Model</span>
<span class="sd">        p = theta  is unknown and initialized to 0.5</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">=</span> <span class="n">Variable</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.5</span><span class="p">),</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Bernoulli PMF</span>
<span class="sd">        p^x (1 - p)^(1 - x)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span> <span class="o">**</span> <span class="n">x</span><span class="p">)</span> <span class="o">*</span> <span class="p">((</span><span class="mf">1.0</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">)</span> <span class="o">**</span> <span class="p">(</span><span class="mf">1.0</span> <span class="o">-</span> <span class="n">x</span><span class="p">))</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">observations</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">prior</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="nb">float</span><span class="p">],</span> <span class="nb">float</span><span class="p">],</span>
        <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-1</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">List</span><span class="p">[</span><span class="nb">float</span><span class="p">]:</span>
        <span class="sd">&quot;&quot;&quot;Maximum a Posteriori Estimation</span>
<span class="sd">        Optimization -&gt; Gradient Ascent (find max using derivative)</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="n">history</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">item</span><span class="p">()]</span>
        <span class="k">for</span> <span class="n">iteration</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
            <span class="n">loglikelihood</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="bp">self</span><span class="p">(</span><span class="n">observations</span><span class="p">)))</span>
            <span class="n">posterior</span> <span class="o">=</span> <span class="n">loglikelihood</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">prior</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="p">))</span>
            <span class="n">posterior</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            
            <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">add_</span><span class="p">(</span><span class="n">lr</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">grad</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Iteration </span><span class="si">{</span><span class="n">iteration</span><span class="si">}</span><span class="s2">: 𝑝̂=</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            
            <span class="n">history</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">item</span><span class="p">())</span>
        <span class="k">return</span> <span class="n">history</span>
            
            
<span class="c1"># Statistical Inference using MAP</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">BernoulliModel</span><span class="p">()</span>
<span class="n">prior</span> <span class="o">=</span> <span class="n">BetaDistribution</span><span class="p">(</span><span class="mf">0.8</span><span class="p">,</span> <span class="mf">0.7</span><span class="p">)</span>
<span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">observations</span><span class="p">,</span> <span class="n">prior</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration 0: 𝑝̂=0.48
Iteration 1: 𝑝̂=0.46
Iteration 2: 𝑝̂=0.45
Iteration 3: 𝑝̂=0.44
Iteration 4: 𝑝̂=0.43
Iteration 5: 𝑝̂=0.43
Iteration 6: 𝑝̂=0.42
Iteration 7: 𝑝̂=0.42
Iteration 8: 𝑝̂=0.41
Iteration 9: 𝑝̂=0.41
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;fivethirtyeight&quot;</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>  <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span> <span class="o">=</span> <span class="p">[</span><span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>

<span class="n">sns</span><span class="o">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">observations</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax1</span><span class="p">,</span> <span class="n">stat</span><span class="o">=</span><span class="s2">&quot;probability&quot;</span><span class="p">,</span> <span class="n">discrete</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s2">&quot;Sample&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;proportion&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">grid</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="s1">&#39;x&#39;</span><span class="p">)</span>

<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">history</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.395</span><span class="p">,</span> <span class="mf">0.505</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s2">&quot;MAP&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;$\hat</span><span class="si">{p}</span><span class="s2">$&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.40</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="map-bernoulli-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_28_0.png" src="../_images/3_statistical_inference_28_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.6 </span><span class="caption-text">Maximum a Posteriori Estimate applied to the basket ball throw example. The objective is to find <span class="math notranslate nohighlight">\(p\)</span> for <span class="math notranslate nohighlight">\(B(n, p)\)</span>. Sample is represented left, and the optimization process base on the MAP right.</span><a class="headerlink" href="#map-bernoulli-fig" title="Permalink to this image">¶</a></p>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that if we do not care about the posterior’s argmax but the posterior distribution itself, this is what we refer to as <strong>Bayesian Inference</strong>. It is the action of guessing in the style of Thomas Bayes. Baye’s style of guessing captures the common sense of knowledge to make better guesses. MAP is, in that sense, only capturing the first mode of the posterior distribution.</p>
</div>
</div>
</div>
<div class="section" id="interval-estimates">
<h3><span class="section-number">4.4.2. </span>Interval Estimates<a class="headerlink" href="#interval-estimates" title="Permalink to this headline">¶</a></h3>
<p>Until this section, we have only discussed point estimators. But what about <strong>Intervals</strong>?
In this section we study <strong>Interval Estimation</strong> for <strong>the means</strong> and <strong>for proportions</strong>.</p>
<div class="section" id="interval-estimation-of-an-expected-value">
<h4><span class="section-number">4.4.2.1. </span>Interval Estimation of an Expected Value<a class="headerlink" href="#interval-estimation-of-an-expected-value" title="Permalink to this headline">¶</a></h4>
<div class="section" id="with-known-variance">
<h5><span class="section-number">4.4.2.1.1. </span>With Known Variance<a class="headerlink" href="#with-known-variance" title="Permalink to this headline">¶</a></h5>
<p>Consider a sample <span class="math notranslate nohighlight">\(X_1, \dots, X_n\)</span>, independent and sampled from the same distribution, for example <span class="math notranslate nohighlight">\(\mathcal{N}(\mu, \sigma^2)\)</span> with <span class="math notranslate nohighlight">\(\mu\)</span> unknown and <span class="math notranslate nohighlight">\(\sigma^2\)</span> known. What are the possible value, believable values of <span class="math notranslate nohighlight">\(\sigma\)</span> given our random sample?</p>
<p>We are interested on knowing what the distribution <span class="math notranslate nohighlight">\(\bar{X}\)</span> looks like. Using MLE, we can apporximate this dsitribution:</p>
<div class="math notranslate nohighlight">
\[
\bar{X} = \frac{1}{2} \sum_{i=1}{n} X_i
\]</div>
<p>We also know from the central limit theorem that its standardized centered and reduced form follows a normal distribution when considering a big enough sample size:</p>
<div class="math notranslate nohighlight">
\[
Z = \frac{\bar{X} - \mu}{\sigma / \sqrt{n}} \sim \mathcal{N}(0, 1)
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">norm</span>


<span class="n">confidence</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">za</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">confidence</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">zb</span> <span class="o">=</span> <span class="n">norm</span><span class="o">.</span><span class="n">ppf</span><span class="p">((</span><span class="mi">1</span> <span class="o">+</span> <span class="n">confidence</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Za = </span><span class="si">{</span><span class="n">za</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Zb =  </span><span class="si">{</span><span class="n">zb</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Za = -1.96
Zb =  1.96
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;fivethirtyeight&quot;</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>  <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">-</span><span class="mf">1.96</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span> <span class="mf">1.96</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.96</span><span class="p">,</span> <span class="mf">1.96</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.96</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1.96</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="mi">0</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$1 - \alpha$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="o">-</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$-z_{\alpha / 2}$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#F6424C&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$z_{\alpha / 2}$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#328008&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.40</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="ic-normal-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_33_0.png" src="../_images/3_statistical_inference_33_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.7 </span><span class="caption-text">Normal Distribution <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span> and <span class="math notranslate nohighlight">\(95\)</span>% range <span class="math notranslate nohighlight">\([-Z_{\alpha / 2}, Z_{\alpha / 2}]\)</span></span><a class="headerlink" href="#ic-normal-fig" title="Permalink to this image">¶</a></p>
</div>
<p>If we want to define a <span class="math notranslate nohighlight">\(95\)</span>% <strong>Interval Estimate</strong> of <span class="math notranslate nohighlight">\(\mu\)</span>, for example, we can refer to the normal distribution graph or table and see that it corresponds to area under the curve within the range <span class="math notranslate nohighlight">\([-1.96, 1.96]\)</span>. Whe can then say that:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
P(-1.96 \leq Z \leq 1.96)                            &amp; = 0.95 \\
P(\bar{X} - \frac{1.96 \sigma}{\sqrt{n}} \leq \mu \leq \bar{X} + \frac{1.96 \sigma}{\sqrt{n}}) &amp; = 0.95 \\ 
\end{align}
\end{split}\]</div>
<p>We can now say that the random interval <span class="math notranslate nohighlight">\(\bar{X} \pm 1.96 \sigma / \sqrt{n}\)</span> is a <span class="math notranslate nohighlight">\(95\)</span>% <strong>Confidence Interval</strong> (CI) for <span class="math notranslate nohighlight">\(\mu\)</span>. <span class="math notranslate nohighlight">\(95\)</span>% is reffered to as the <strong>Confidence Level</strong>, and states that <span class="math notranslate nohighlight">\(P(\mu \in CI) =  1 - \alpha\)</span>, with <span class="math notranslate nohighlight">\(alpha\)</span> the <strong>Significance Level</strong>.</p>
</div>
<div class="section" id="with-unknown-variance">
<h5><span class="section-number">4.4.2.1.2. </span>With Unknown Variance<a class="headerlink" href="#with-unknown-variance" title="Permalink to this headline">¶</a></h5>
<p>Let reconsider the same framework but this times without knowing <span class="math notranslate nohighlight">\(\sigma^2\)</span>. Our best estimation of the variance is <span class="math notranslate nohighlight">\(S_n^{*2}\)</span> and <strong>Fisher’s Theorem</strong> telles us that <span class="math notranslate nohighlight">\(\frac{n-1}{\sigma^2} S_n^{*2} \sim \chi_{n-1}^2\)</span>. We can then define the <strong>Student Statistic</strong>:</p>
<div class="math notranslate nohighlight">
\[
T_{n-1} = \frac{\frac{\bar{X} - \mu}{\sigma / \sqrt{n}}}{\sqrt{\frac{\frac{n-1}{\sigma^2} S^{*2}}{n-1}}}
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">t</span>


<span class="n">confidence</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">ta</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">((</span><span class="mi">1</span> <span class="o">-</span> <span class="n">confidence</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>
<span class="n">tb</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">((</span><span class="mi">1</span> <span class="o">+</span> <span class="n">confidence</span><span class="p">)</span> <span class="o">/</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">9</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Ta = </span><span class="si">{</span><span class="n">ta</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Tb =  </span><span class="si">{</span><span class="n">tb</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ta = -2.26
Tb =  2.26
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;fivethirtyeight&quot;</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>  <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">-</span><span class="mf">2.26</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span> <span class="mf">2.26</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.26</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">2.26</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;g&quot;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="mi">0</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$1 - \alpha$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="o">-</span><span class="mi">3</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$-t_{9,\alpha / 2}$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#F6424C&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="mi">3</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$t_{9,\alpha / 2}$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#328008&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.40</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="ic-t-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_38_0.png" src="../_images/3_statistical_inference_38_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.8 </span><span class="caption-text">Student Distribution <span class="math notranslate nohighlight">\(T_9\)</span> and <span class="math notranslate nohighlight">\(95\)</span>% range <span class="math notranslate nohighlight">\([-t_{9, \alpha / 2}, t_{9, \alpha / 2}]\)</span></span><a class="headerlink" href="#ic-t-fig" title="Permalink to this image">¶</a></p>
</div>
<p>As we want to obtain a confidence interval for <span class="math notranslate nohighlight">\(\mu\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
P(-t_{n-1} \leq T_{n-1,\alpha/2} \leq t_{n-1,\alpha/2})                            &amp; = 0.95 \\
P(\bar{X} - t_{n-1,\alpha/2} \frac{S^*}{\sqrt{n}} \leq \mu \leq \bar{X} + t_{n-1,\alpha/2} \frac{S^*}{\sqrt{n}}) &amp; = 0.95 \\ 
\end{align}
\end{split}\]</div>
<p>We can finally say that <span class="math notranslate nohighlight">\(\bar{X} \pm t_{n-1} \frac{S^*}{\sqrt{n}}\)</span> is a <span class="math notranslate nohighlight">\(95\)</span>% <strong>Confidance Interval</strong> for <span class="math notranslate nohighlight">\(\mu\)</span>.</p>
</div>
</div>
<div class="section" id="interval-estimation-of-a-proportion">
<h4><span class="section-number">4.4.2.2. </span>Interval Estimation of a Proportion<a class="headerlink" href="#interval-estimation-of-a-proportion" title="Permalink to this headline">¶</a></h4>
<p>A similar approach to the one discussed for the interval estimation of a mean can be applied to estimating an interval for a <strong>Proportion</strong>. Consider a Binomial test with <span class="math notranslate nohighlight">\(n\)</span> large and let <span class="math notranslate nohighlight">\(X\)</span> denote the number of successes where <span class="math notranslate nohighlight">\(p\)</span>, the probability of one success is unknown.</p>
<p>The central limit theorem tells us that:</p>
<div class="math notranslate nohighlight">
\[
Z = \frac{\bar{X} - np}{\sigma / \sqrt{np(1-p)}} \sim \mathcal{N}(0, 1)
\]</div>
<p>In that regard, if we want to define a <span class="math notranslate nohighlight">\(100(1 - \alpha)\)</span>% confidence interval:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
P(-Z_{\alpha / 2} \leq Z \leq Z_{\alpha / 2}) &amp; = 0.95 \\
P(\frac{X}{n} - Z_{\alpha / 2} \sqrt{\frac{\frac{Y}{n} (1 - \frac{Y}{n})}{n}} \leq p \leq \frac{X}{n} + Z_{\alpha / 2} \sqrt{\frac{\frac{Y}{n} (1 - \frac{Y}{n})}{n}}) &amp; \approx 0.95 \\ 
\end{align}
\end{split}\]</div>
</div>
</div>
</div>
<div class="section" id="hypothesis-testing">
<h2><span class="section-number">4.5. </span>Hypothesis Testing<a class="headerlink" href="#hypothesis-testing" title="Permalink to this headline">¶</a></h2>
<p>Statistics are great tools for <strong>Hypothesis Testing</strong>, verifying assumptions, claims, and beliefs based on a data sample. Every hypothesis testing is performed following the given steps:</p>
<ul class="simple">
<li><p>State a <strong>Hypothesis</strong></p></li>
<li><p>Select appropriate <strong>Test Statistic</strong></p></li>
<li><p>Specify the <strong>Significance Level</strong></p></li>
<li><p>State the <strong>Decision Rule</strong> regarding the hypothesis</p></li>
<li><p>Compute the <strong>Sample Statistic</strong></p></li>
<li><p><strong>Conclude</strong> on the hypothesis</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Different statistics and different test types are chosen depending on the study’s framework. A few of them are discussed throughout this chapter. However, the majority of those tests follow the same kind of method.</p>
</div>
<div class="section" id="one-sample-testing">
<h3><span class="section-number">4.5.1. </span>One-Sample Testing<a class="headerlink" href="#one-sample-testing" title="Permalink to this headline">¶</a></h3>
<p>The first step of hypothesis testing is to formulate what is referred to as the <strong>Null</strong> and the <strong>Alternative</strong> hypothesis. The <strong>Null Hypothesis</strong> <span class="math notranslate nohighlight">\(H_0\)</span> denotes the statement, the population parameter subject to the test. The <strong>Alternative Hypothesis</strong> <span class="math notranslate nohighlight">\(H_1\)</span>, is the opposite statement. If we have enough evidence to reject the null hypothesis, the alternative hypothesis cannot be rejected and assumed to be true. If we do not, the alternative hypothesis is therefore rejected. The following are plosible respectively null and alternative hypothesis:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H_0:\;parameter=X &amp;&amp; H_1:\;parameter\neq X &amp;&amp; \text{Two-Tailed Test} \\
H_0:\;parameter\leq X &amp;&amp; H_1:\;parameter\gt X &amp;&amp; \text{One-Tailed Test} \\
H_0:\;parameter\geq X &amp;&amp; H_1:\;parameter\lt X &amp;&amp; \text{One-Tailed Test}
\end{align}
\end{split}\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The belief we want to test, the hypothesis, is <span class="math notranslate nohighlight">\(H_1\)</span>. By refuting <span class="math notranslate nohighlight">\(H_0\)</span>, we can say we have enough evidence not to deny <span class="math notranslate nohighlight">\(H_1\)</span>.</p>
</div>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;fivethirtyeight&quot;</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>  <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="p">,</span> <span class="n">ax1</span><span class="p">,</span> <span class="n">ax3</span> <span class="o">=</span> <span class="p">[</span><span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">)]</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">))</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;k&quot;</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">-</span><span class="mf">2.26</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">-</span><span class="mf">1.83</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span> <span class="mf">2.26</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span> <span class="mf">1.83</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mf">2.26</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.83</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">2.26</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1.83</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">t</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="mi">9</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">set_axis_off</span><span class="p">()</span>

<span class="n">ax1</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s2">&quot;Two-Tailed&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s2">&quot;One-Tailed&quot;</span><span class="p">)</span>
<span class="n">ax3</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s2">&quot;One-Tailed&quot;</span><span class="p">)</span>


<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="ht-tailed-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_42_0.png" src="../_images/3_statistical_inference_42_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.9 </span><span class="caption-text">One-Tailed and Two-Tailed satistic test.</span><a class="headerlink" href="#ht-tailed-fig" title="Permalink to this image">¶</a></p>
</div>
<p>A <strong>Test Statistic</strong> is a quantity computed given a sample. Its value is responsible for deciding whether or not the null hypothesis is rejected. The <strong>Z-statistic</strong>, the <strong>t-statistic</strong>, and the <strong>chi-statistic</strong> are examples of such test statistics. It is often presented in the following form:</p>
<div class="math notranslate nohighlight">
\[
T = \frac{\text{Sample Statistic} - \text{Hypthesis Value}}{\text{Sandard Error of Sample Statistic}}
\]</div>
<p>After defining this statistic, by considering the region that is consistent with <span class="math notranslate nohighlight">\(H_0\)</span> and the region which is not, the <strong>Critical Region</strong>, we can compare its value and observe in which of those regions it is found. This allows us to conclude. The value that allows to validate or reject the hypothesis is <span class="math notranslate nohighlight">\(\alpha\)</span> called the <strong>Significance</strong>. It represented the probability of rejecting the null hypothesis when it is, in fact, true. This value need to be set before computing any value and cannot be changed during and after the test.</p>
<ul class="simple">
<li><p>For a <strong>Left One-Tailed Test</strong>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
&amp; H_1:\;\text{parameter}&lt;X \\
&amp; \text{Reject}\;H_0:\;\text{if}\;T&lt;\text{Critical Value}
\end{align}
\end{split}\]</div>
<ul class="simple">
<li><p>For a <strong>Right One-Tailed Test</strong>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
&amp; H_1:\;\text{parameter}&gt;X \\
&amp; \text{Reject}\;H_0:\;\text{if}\;T&gt;\text{Critical Value}
\end{align}
\end{split}\]</div>
<ul class="simple">
<li><p>For a <strong>Two-Tailed Test</strong>:</p></li>
</ul>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
&amp; H_1:\;\text{parameter}\neq X \\
&amp; \text{Reject}\;H_0:\;\text{if}&amp; T&lt;\text{Lower Critical Value} \\
&amp; &amp; \text{or}\;T&gt;\text{Upper Critical Value}
\end{align}
\end{split}\]</div>
<p>The <strong>Power</strong> of a test is given by <span class="math notranslate nohighlight">\(1-\beta\)</span> where <span class="math notranslate nohighlight">\(\beta\)</span> is the significance of <span class="math notranslate nohighlight">\(H_1\)</span>.</p>
<p>Let us consider some examples:</p>
<ul class="simple">
<li><p><strong>Two-Tailed Test</strong>:</p></li>
</ul>
<p>A factory is responsible for manufacturing M4 screws. An employee believes the average socket-head cap diameter is not <span class="math notranslate nohighlight">\(3\)</span> mm. Using 45 samples, they measure the average diameter produced by their machine and found <span class="math notranslate nohighlight">\(2.8\)</span> mm with plus or minus <span class="math notranslate nohighlight">\(0.15\)</span> mm.</p>
<p>In this problem, we can define:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H_0:\;\mu = 3 \\
H_1:\;\mu \neq 3
\end{align}
\end{split}\]</div>
<p>Let us choose a confidence of <span class="math notranslate nohighlight">\(95\)</span>%. In this case, as the sample size is greater than <span class="math notranslate nohighlight">\(30\)</span>, we can call the Central Limit Theorem and use the Z-statistic.</p>
<div class="math notranslate nohighlight">
\[
z_c = \frac{\bar{x} - \mu_0}{s / \sqrt{n}} = \frac{2.8 - 3.0}{0.15 / \sqrt{45}} \approx -8.9
\]</div>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;fivethirtyeight&quot;</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>  <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">-</span><span class="mf">1.96</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span> <span class="mf">1.96</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">((</span><span class="mf">2.8</span> <span class="o">-</span> <span class="mf">3.0</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">0.15</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">45</span><span class="p">)),</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#F6424C&quot;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mf">1.96</span><span class="p">,</span> <span class="mf">1.96</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="mf">1.96</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1.96</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="mi">0</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$1 - \alpha$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="o">-</span><span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$-z_{\alpha / 2}$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="mf">2.5</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$z_{\alpha / 2}$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="o">-</span><span class="mf">8.5</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$z_c$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#F6424C&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.40</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="ht-ex1-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_46_0.png" src="../_images/3_statistical_inference_46_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.10 </span><span class="caption-text">Two-Tailed example. The Z-value is in the rejection zone.</span><a class="headerlink" href="#ht-ex1-fig" title="Permalink to this image">¶</a></p>
</div>
<p>Looking at the <span class="math notranslate nohighlight">\(\mathcal{N}(0, 1)\)</span> pdf, we can observe that our statistic value <span class="math notranslate nohighlight">\(z_c\)</span> is lower than <span class="math notranslate nohighlight">\(-z_{0.025} = -1.96\)</span>. It is positioned in the rejection zone. In this case, we can reject the null hypothesis and conclude that with a <span class="math notranslate nohighlight">\(95\)</span>% confidence, the machine does not hold.</p>
<ul class="simple">
<li><p><strong>Left One-Tailed Test</strong>:</p></li>
</ul>
<p>A company is manufacturing light bulbs with an average lifespan of <span class="math notranslate nohighlight">\(1.5k\)</span> hours. An engineer believes this value to be less. Using 15 samples, he measures the average lifespan to be <span class="math notranslate nohighlight">\(1.1k\)</span> hours with a standard deviation of <span class="math notranslate nohighlight">\(0.12k\)</span>.</p>
<p>In this problem, we can define:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H_0: \mu \geq 1.5k \\
H_1: \mu &lt; 1.5k
\end{align}
\end{split}\]</div>
<p>Let us consider a confidence of <span class="math notranslate nohighlight">\(99\)</span>%. There are less than 30 samples, and the population standard deviation is unknown. We will then use a t-statistic:</p>
<div class="math notranslate nohighlight">
\[
t_c = \frac{\bar{x} - \mu_0}{s / \sqrt{n}} = \frac{1.1 - 1.5}{0.12 / \sqrt{15}} \approx -12.9
\]</div>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s2">&quot;fivethirtyeight&quot;</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span>  <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">(</span><span class="o">-</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.99</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">axvline</span><span class="p">((</span><span class="mf">1.1</span> <span class="o">-</span> <span class="mf">1.5</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">0.12</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">15</span><span class="p">)),</span> <span class="n">linestyle</span><span class="o">=</span><span class="s2">&quot;--&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#F6424C&quot;</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.99</span><span class="p">,</span> <span class="mi">14</span><span class="p">),</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">4</span><span class="p">,</span> <span class="o">-</span><span class="n">t</span><span class="o">.</span><span class="n">ppf</span><span class="p">(</span><span class="mf">0.99</span><span class="p">,</span> <span class="mi">14</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.4</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="mi">0</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$1 - \alpha$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="o">-</span><span class="mf">4.5</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$-t_{\alpha, n-1}$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#008FD5&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">text</span><span class="p">(</span>
    <span class="o">-</span><span class="mf">11.5</span><span class="p">,</span> <span class="mf">0.10</span><span class="p">,</span> <span class="sa">r</span><span class="s2">&quot;$t_c$&quot;</span><span class="p">,</span> <span class="n">horizontalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span> <span class="n">verticalalignment</span><span class="o">=</span><span class="s1">&#39;center&#39;</span><span class="p">,</span>
    <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#F6424C&quot;</span><span class="p">,</span> <span class="n">weight</span><span class="o">=</span><span class="s2">&quot;bold&quot;</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.40</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="ht-ex2-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_50_0.png" src="../_images/3_statistical_inference_50_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.11 </span><span class="caption-text">Left One-Tailed example. The t-value is in the rejection zone.</span><a class="headerlink" href="#ht-ex2-fig" title="Permalink to this image">¶</a></p>
</div>
<p>By looking a the pdf of a t-distribution with <span class="math notranslate nohighlight">\(n-1\)</span> degrees of freedom (df), we can observe our statistic value is way lower than the critical value <span class="math notranslate nohighlight">\(t_{0.01, 14} = -2.62\)</span>. In this sense, we can reject the null hypothesis with a confidence of <span class="math notranslate nohighlight">\(99\)</span>%.</p>
</div>
<div class="section" id="two-sample-testing">
<h3><span class="section-number">4.5.2. </span>Two-Sample Testing<a class="headerlink" href="#two-sample-testing" title="Permalink to this headline">¶</a></h3>
<p>Hypothesis testing does not always infer belief in one unique sample. You may want to compare and assess the belief between two different samples. This is what <strong>Two-Sample Testing</strong> is designed for. A two-sample test can be transformed into a one-sample test by applying a simple trick. Let us consider an example.</p>
<p>Consider two basketball teams. Team A claims that their players have a number of 3 points field goals significantly different than team B. During the season, team A has <span class="math notranslate nohighlight">\(15\)</span> players and yield a mean of <span class="math notranslate nohighlight">\(35\)</span> with a standard deviation of <span class="math notranslate nohighlight">\(5.2\)</span> per player, against <span class="math notranslate nohighlight">\(13\)</span> players for team B with a mean of <span class="math notranslate nohighlight">\(28\)</span> and a standard deviation of <span class="math notranslate nohighlight">\(3.7\)</span>. Is there a significant difference between the two teams? Let us consider a <span class="math notranslate nohighlight">\(95\)</span>% confidence.</p>
<p>In this problem we can define:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
H_0: \mu_A - \mu_B = 0 \\
H_1: \mu_A - \mu_B \neq 0
\end{align}
\end{split}\]</div>
<p>Given the lower sample size, we consider a t-statistic with degrees of freedom given by:</p>
<div class="math notranslate nohighlight">
\[
df = \frac{(\frac{s_A^2}{n_A} + \frac{s_B^2}{n_B})^2}{\frac{(s_A^2/n_A)^2}{n_A-1} + \frac{(s_B^2/n_B)^2}{n_B-1}} = \frac{(\frac{5.2^2}{15} + \frac{3.7^2}{13})^2}{\frac{(5.2^2/15)^2}{14} + \frac{(3.7^2/13)^2}{12}} \approx 9
\]</div>
<p>The statistic value for this test needs to be less than <span class="math notranslate nohighlight">\(-t_{0.025, 9}\)</span> or greater than <span class="math notranslate nohighlight">\(t_{0.025, 9}\)</span> to be rejected with <span class="math notranslate nohighlight">\(t_{0.025, 9} \approx -2.26\)</span>.</p>
<div class="math notranslate nohighlight">
\[
t_c = \frac{(\bar{x_A} - \bar{x_B}) - (\mu_A - \mu_B)}{\sqrt{\frac{s_A^2}{n_A} + \frac{s_B^2}{n_B}}} 
    = \frac{(35 - 28) - 0}{\sqrt{\frac{5.2^2}{15} + \frac{3.7^2}{13}}}
    \approx 4.14
\]</div>
<p>We can now conclude that there is a significant difference at <span class="math notranslate nohighlight">\(5\)</span>% between the two teams.</p>
</div>
<div class="section" id="p-value-method">
<h3><span class="section-number">4.5.3. </span>P-Value Method<a class="headerlink" href="#p-value-method" title="Permalink to this headline">¶</a></h3>
<p>The <strong>P-Value</strong> method is commonly used to decide on the rejection of the null hypothesis. It is an extension of the methods presented above. Instead of just considering the statistic position compared to the critical value of a given significance level, we consider the hole <strong>rejection area</strong>. This rejection area corresponds to the probability of rejecting the null hypothesis with a given significance level. The new decision rule is then:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\text{p-value} &lt; \alpha: &amp; \; \text{Succeed to reject} \; H_0 \\
\text{p-value} \geq \alpha: &amp; \; \text{Failed to reject} \; H_0 \\
\end{align}
\end{split}\]</div>
<p>Let us reuse the example of the one-sample left one-tailed test with the light bulb life span. By referring to a <span class="math notranslate nohighlight">\(\text{p-value}\)</span> table of a t-distribution with <span class="math notranslate nohighlight">\(14\)</span> degrees of freedom, we find that <span class="math notranslate nohighlight">\(\text{p-value}=1.8\times10^{-9}\)</span> which is way lower than <span class="math notranslate nohighlight">\(\alpha=0.05\)</span>. We can then conclude that H_0 is rejected with a confidence of <span class="math notranslate nohighlight">\(95\)</span>%.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">t</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="n">t_stat</span> <span class="o">=</span> <span class="p">(</span><span class="mf">1.1</span> <span class="o">-</span> <span class="mf">1.5</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mf">0.12</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="mi">15</span><span class="p">))</span>
<span class="n">p_value</span> <span class="o">=</span> <span class="n">t</span><span class="o">.</span><span class="n">sf</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">t_stat</span><span class="p">),</span> <span class="mi">14</span><span class="p">)</span>             <span class="c1"># times 2 for two-tailed tests</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;t-statistic: </span><span class="si">{</span><span class="n">t_stat</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;p-value    : </span><span class="si">{</span><span class="n">p_value</span><span class="si">:</span><span class="s2">.2g</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>t-statistic: -12.91
p-value    : 1.8e-09
</pre></div>
</div>
</div>
</div>
</div>
<div class="section" id="hypthesis-tests-zoo">
<h3><span class="section-number">4.5.4. </span>Hypthesis Tests Zoo<a class="headerlink" href="#hypthesis-tests-zoo" title="Permalink to this headline">¶</a></h3>
<p>Here is a non-exhaustive table of <strong>Hypothesis Tests</strong>:</p>
<table class="colwidths-auto table">
<thead>
<tr class="row-odd"><th class="text-align:left head"><p>Data Type</p></th>
<th class="text-align:center head"><p>Variable</p></th>
<th class="text-align:center head"><p>One-Sample</p></th>
<th class="text-align:center head"><p>Two-Sample</p></th>
<th class="text-align:center head"><p>Multi-Sample</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-align:left"><p>Continuous &amp; Normality assumption</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\mu\)</span></p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\begin{align}H_0&amp;:\;\mu=\mu_0 \\ H_1&amp;:\;\mu\neq\mu_0\end{align}\\\textbf{T-Test}\)</span></p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\begin{align}H_0&amp;:\;\mu_0=\mu_2 \\ H_1&amp;:\;\mu_0\neq\mu_1\end{align}\\\textbf{T-Test}\)</span></p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\begin{align}H_0&amp;:\;\mu_0=\dots=\mu_k \\ H_1&amp;:\;\text{At least one mean is different}\end{align}\\\textbf{Analysis of Variance}\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Continuous &amp; Normality assumption</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\sigma\)</span></p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\begin{align}H_0&amp;:\;\sigma=\sigma_0 \\ H_1&amp;:\;\sigma\neq\sigma_0\end{align}\\\textbf{Chi-Square Test}\)</span></p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\begin{align}H_0&amp;:\;\sigma_0=\sigma_2 \\ H_1&amp;:\;\sigma_0\neq\sigma_1\end{align}\\\textbf{F-Test}\)</span></p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\begin{align}H_0&amp;:\;\sigma_0=\dots=\sigma_k \\ H_1&amp;:\;\text{One is different}\end{align}\\\textbf{Bartlett's Test}\)</span></p></td>
</tr>
<tr class="row-even"><td class="text-align:left"><p>Continuous &amp; Non Normal</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\eta\)</span></p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\begin{align}H_0&amp;:\;\eta=\eta_0 \\ H_1&amp;:\;\eta\neq\eta_0\end{align}\\\textbf{Wilcoxon Test}\)</span></p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\begin{align}H_0&amp;:\;\eta_0=\eta_2 \\ H_1&amp;:\;\eta_0\neq\eta_1\end{align}\\\textbf{Mann-Whitney Test}\)</span></p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\begin{align}H_0&amp;:\;\eta_0=\dots=\eta_k \\ H_1&amp;:\;\text{One is different}\end{align}\\\textbf{Kruskal-Wallis Test}\)</span></p></td>
</tr>
<tr class="row-odd"><td class="text-align:left"><p>Discrete</p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\pi\)</span></p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\begin{align}H_0&amp;:\;\pi=\pi_0 \\ H_1&amp;:\;\pi\neq\pi_0\end{align}\\\textbf{Proportion Test}\)</span></p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\begin{align}H_0&amp;:\;\pi_0=\pi_2 \\ H_1&amp;:\;\pi_0\neq\pi_1\end{align}\\\textbf{Proportion Test}\)</span></p></td>
<td class="text-align:center"><p><span class="math notranslate nohighlight">\(\begin{align}H_0&amp;:\;\pi_0=\dots=\pi_k \\ H_1&amp;:\;\text{One is different}\end{align}\\\textbf{Binomial Analysis of Means}\)</span></p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="applications">
<h2><span class="section-number">4.6. </span>Applications<a class="headerlink" href="#applications" title="Permalink to this headline">¶</a></h2>
<p>Statistical Inference and Probabilities are key to Machine and Deep Learning, and <strong>Applied Mathematics</strong> in general. This section details common uses of those concepts especially to the use of <strong>Machine Learning</strong>.</p>
<div class="section" id="linear-vs-logistic-regression">
<h3><span class="section-number">4.6.1. </span>Linear VS Logistic Regression<a class="headerlink" href="#linear-vs-logistic-regression" title="Permalink to this headline">¶</a></h3>
<p>Let us consider the Breast Cancer Dataset example for PCA in the <a class="reference internal" href="1_linear_algebra.html"><span class="doc std std-doc">Linear Algebra Chapter</span></a>. To simplify the explanations, we apply PCA on the features to obtain only one feature, the projection on to the first principal component, capturing most variation. As a reminder our goald with this dataset is to <strong>classify</strong> a person as having a breast cancer <span class="math notranslate nohighlight">\(1\)</span> or not <span class="math notranslate nohighlight">\(0\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.datasets</span> <span class="kn">import</span> <span class="n">load_breast_cancer</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>

<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s2">&quot;display.max_columns&quot;</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>


<span class="c1"># To Normalize Data (Mean Center and Normalize Variation)</span>
<span class="n">sc</span> <span class="o">=</span> <span class="n">StandardScaler</span><span class="p">()</span>

<span class="c1"># Load Breast Cancer dataset in memory</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">load_breast_cancer</span><span class="p">(</span><span class="n">return_X_y</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">sc</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">data</span><span class="o">.</span><span class="n">data</span><span class="p">),</span> <span class="n">data</span><span class="o">.</span><span class="n">target</span>

<span class="c1"># Split Dataset</span>
<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.33</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">42</span><span class="p">)</span>

<span class="c1"># Show data as a dataframe to display infos table</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">X</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">data</span><span class="o">.</span><span class="n">feature_names</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean radius</th>
      <th>mean texture</th>
      <th>mean perimeter</th>
      <th>mean area</th>
      <th>...</th>
      <th>worst concavity</th>
      <th>worst concave points</th>
      <th>worst symmetry</th>
      <th>worst fractal dimension</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.097064</td>
      <td>-2.073335</td>
      <td>1.269934</td>
      <td>0.984375</td>
      <td>...</td>
      <td>2.109526</td>
      <td>2.296076</td>
      <td>2.750622</td>
      <td>1.937015</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.829821</td>
      <td>-0.353632</td>
      <td>1.685955</td>
      <td>1.908708</td>
      <td>...</td>
      <td>-0.146749</td>
      <td>1.087084</td>
      <td>-0.243890</td>
      <td>0.281190</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.579888</td>
      <td>0.456187</td>
      <td>1.566503</td>
      <td>1.558884</td>
      <td>...</td>
      <td>0.854974</td>
      <td>1.955000</td>
      <td>1.152255</td>
      <td>0.201391</td>
    </tr>
    <tr>
      <th>3</th>
      <td>-0.768909</td>
      <td>0.253732</td>
      <td>-0.592687</td>
      <td>-0.764464</td>
      <td>...</td>
      <td>1.989588</td>
      <td>2.175786</td>
      <td>6.046041</td>
      <td>4.935010</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.750297</td>
      <td>-1.151816</td>
      <td>1.776573</td>
      <td>1.826229</td>
      <td>...</td>
      <td>0.613179</td>
      <td>0.729259</td>
      <td>-0.868353</td>
      <td>-0.397100</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 30 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 569 entries, 0 to 568
Data columns (total 30 columns):
 #   Column                   Non-Null Count  Dtype  
---  ------                   --------------  -----  
 0   mean radius              569 non-null    float64
 1   mean texture             569 non-null    float64
 2   mean perimeter           569 non-null    float64
 3   mean area                569 non-null    float64
 4   mean smoothness          569 non-null    float64
 5   mean compactness         569 non-null    float64
 6   mean concavity           569 non-null    float64
 7   mean concave points      569 non-null    float64
 8   mean symmetry            569 non-null    float64
 9   mean fractal dimension   569 non-null    float64
 10  radius error             569 non-null    float64
 11  texture error            569 non-null    float64
 12  perimeter error          569 non-null    float64
 13  area error               569 non-null    float64
 14  smoothness error         569 non-null    float64
 15  compactness error        569 non-null    float64
 16  concavity error          569 non-null    float64
 17  concave points error     569 non-null    float64
 18  symmetry error           569 non-null    float64
 19  fractal dimension error  569 non-null    float64
 20  worst radius             569 non-null    float64
 21  worst texture            569 non-null    float64
 22  worst perimeter          569 non-null    float64
 23  worst area               569 non-null    float64
 24  worst smoothness         569 non-null    float64
 25  worst compactness        569 non-null    float64
 26  worst concavity          569 non-null    float64
 27  worst concave points     569 non-null    float64
 28  worst symmetry           569 non-null    float64
 29  worst fractal dimension  569 non-null    float64
dtypes: float64(30)
memory usage: 133.5 KB
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.decomposition</span> <span class="kn">import</span> <span class="n">PCA</span>


<span class="n">pca</span> <span class="o">=</span> <span class="n">PCA</span><span class="p">(</span><span class="n">n_components</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">pca_X_train</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_train</span><span class="p">)</span>
<span class="n">pca_X_test</span> <span class="o">=</span> <span class="n">pca</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_data</span><span class="p">(</span><span class="n">ax</span><span class="p">:</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span> <span class="n">pca_X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">lc</span><span class="p">,</span> <span class="n">ln</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span>    <span class="c1"># Ensure only one label for legend</span>
    <span class="k">for</span> <span class="n">coord</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pca_X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="s2">&quot;r&quot;</span> <span class="k">if</span> <span class="n">label</span> <span class="k">else</span> <span class="s2">&quot;#008FD5&quot;</span>
        <span class="n">m</span> <span class="o">=</span> <span class="s2">&quot;&lt;&quot;</span> <span class="k">if</span> <span class="n">label</span> <span class="k">else</span> <span class="s2">&quot;o&quot;</span>

        <span class="n">l</span> <span class="o">=</span> <span class="s2">&quot;Cancer&quot;</span> <span class="k">if</span> <span class="n">label</span> <span class="k">else</span> <span class="s2">&quot;Normal&quot;</span>
        <span class="k">if</span> <span class="n">l</span> <span class="o">==</span> <span class="s2">&quot;Cancer&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">lc</span><span class="p">:</span> <span class="n">lc</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">l</span> <span class="o">==</span> <span class="s2">&quot;Normal&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ln</span><span class="p">:</span> <span class="n">ln</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span> <span class="n">l</span> <span class="o">=</span> <span class="s2">&quot;_&quot;</span>
            
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">coord</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">l</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;PCA 1&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;probability of breast cancer&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>


<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">plot_data</span><span class="p">(</span><span class="n">ax</span><span class="p">,</span> <span class="n">pca_X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="lr-breast-cancer-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_59_0.png" src="../_images/3_statistical_inference_59_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.12 </span><span class="caption-text">Visualization of the firs principal axis against the probability of having a breast cancer for the training data.</span><a class="headerlink" href="#lr-breast-cancer-fig" title="Permalink to this image">¶</a></p>
</div>
<p>As a first step, we can observe that the random variable <span class="math notranslate nohighlight">\(Y\)</span> we are studying, the probability of a patient with breast cancer or not, is binary and follows a Bernoulli distribution <span class="math notranslate nohighlight">\(B(p)\)</span>. We are interested in estimating the parameter <span class="math notranslate nohighlight">\(p\)</span> of that distribution given our dataset.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
Y = \begin{cases}
 1 &amp; \text{ with probability } p \\ 
 0 &amp; \text{ with probability } 1-p 
\end{cases}
\end{split}\]</div>
<p>In this example, we wan to find a model that gives us this probability given a data point, patient features, or feature in this case:</p>
<div class="math notranslate nohighlight">
\[
p(x) = P(Y=1\;|\;X=x)
\]</div>
<p>If there is a linear between X and Y, we can use a Linear Regression as presented in the <a class="reference internal" href="1_linear_algebra.html"><span class="doc std std-doc">Linear Algebra Chapter</span></a>. As a reminder, here is the definition of a linear model applied to our study case:</p>
<div class="math notranslate nohighlight">
\[
p(x) = \beta_0 + \beta_1 x
\]</div>
<p>One problem with such a formulation is that <span class="math notranslate nohighlight">\(p(x)\)</span> can take negative values and positive values above 1. This cannot happened for probabilities. One way to fix this issue is to constrain this model by applying a monolitic function that maps <span class="math notranslate nohighlight">\(z = \beta_0 + \beta_1 x\)</span> to the <span class="math notranslate nohighlight">\([0, 1]\)</span> range. The <strong>sigmoid</strong> function, sometimes called the <strong>logistic</strong> function, is such a function:</p>
<div class="math notranslate nohighlight">
\[
\sigma(z) = \frac{1}{1 + e^{-z}}
\]</div>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">sigmoid</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">z</span><span class="p">:</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;x&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;y&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="lr-sigmoid-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_63_0.png" src="../_images/3_statistical_inference_63_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.13 </span><span class="caption-text">Sigmoid function.</span><a class="headerlink" href="#lr-sigmoid-fig" title="Permalink to this image">¶</a></p>
</div>
<p>We are now performing what is called <strong>Logistic Regression</strong>. The probability of a given data point to correspond to a patient with breast cancer is now given by:</p>
<div class="math notranslate nohighlight">
\[
p(x) = \sigma(z) = \frac{1}{1 + e^{-\beta_0 - \beta_1 x}}
\]</div>
<p>This equation can be rewritten as follow:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{align}
\frac{p(x)}{1 - p(x)}      &amp; = e^{\beta_0 + \beta_1 x} \\
log(\frac{p(x)}{1 - p(x)}) &amp; = \beta_0 + \beta_1 x
\end{align}
\end{split}\]</div>
<p>The left factor is referred to as the logits, or log-odds, and the internal log factor as the odds. It is now just a matter of fitting a line into the logits projection, in other world estimating the coefficients <span class="math notranslate nohighlight">\(\beta_0\)</span> and <span class="math notranslate nohighlight">\(\beta_1\)</span>. This can be achieved using the MLE.</p>
<div class="math notranslate nohighlight">
\[
\begin{align}
\prod_{i=1}^n P(Y=y_i\;|\;X=x_i) = \prod_{i=1}^n p(x_i)^{y_i} (1 - p(x_i))^{1 - y_i}
\end{align}
\]</div>
<p>As a reminder, maximizing the likelihood is the same as maximizing the log-likelihood:</p>
<div class="math notranslate nohighlight">
\[
\sum_{i=1}^n y_i log\;p(x_i) + (1 - y_i) log\;(1 - p(x_i))
\]</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Note that minimizing the negative loglikelihood is equivalent to minimizing the cross-entropy defined by Shannon, in this case the binary cross-entropy.</p>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">torch.optim</span> <span class="kn">import</span> <span class="n">SGD</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>
<span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">42</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">LinearRegression</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LinearRegression</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Train] Linear   Regression [</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">iterations</span><span class="si">}</span><span class="s2">] acc:</span><span class="si">{</span><span class="n">acc</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
    
    
<span class="k">class</span> <span class="nc">LogisticRegression</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">(</span><span class="n">LogisticRegression</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">logits</span><span class="p">)</span>
    
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">lr</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span> <span class="n">iterations</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">BCELoss</span><span class="p">()</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">SGD</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">lr</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
        
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">iterations</span><span class="p">):</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
            <span class="n">y_pred</span> <span class="o">=</span> <span class="bp">self</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
            <span class="n">loss</span> <span class="o">=</span> <span class="n">criterion</span><span class="p">(</span><span class="n">y_pred</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
            <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
        <span class="n">acc</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Train] Logistic Regression [</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">iterations</span><span class="si">}</span><span class="s2">] acc:</span><span class="si">{</span><span class="n">acc</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
            
            
<span class="n">linear_reg</span> <span class="o">=</span> <span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">linear_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pca_X_train</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>

<span class="n">logistic_reg</span> <span class="o">=</span> <span class="n">LogisticRegression</span><span class="p">()</span>
<span class="n">logistic_reg</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pca_X_train</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Train] Linear   Regression [100/100] acc:66.40%
[Train] Logistic Regression [100/100] acc:83.20%
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">pca_X_test</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">linear_reg</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">acc</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Test] Linear   Regression acc:</span><span class="si">{</span><span class="n">acc</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>

<span class="n">y_pred</span> <span class="o">=</span> <span class="n">logistic_reg</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">acc</span> <span class="o">=</span> <span class="p">((</span><span class="n">y_pred</span> <span class="o">&gt;</span> <span class="mf">0.5</span><span class="p">)</span> <span class="o">==</span> <span class="n">y</span><span class="p">)</span><span class="o">.</span><span class="n">float</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="mi">100</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;[Test] Logistic Regression acc:</span><span class="si">{</span><span class="n">acc</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[Test] Linear   Regression acc:70.21%
[Test] Logistic Regression acc:82.98%
</pre></div>
</div>
</div>
</div>
<div class="cell tag_hide-input tag_remove-output docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ion</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">style</span><span class="o">.</span><span class="n">use</span><span class="p">(</span><span class="s1">&#39;fivethirtyeight&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">plot_data</span><span class="p">(</span><span class="n">ax</span><span class="p">:</span> <span class="n">plt</span><span class="o">.</span><span class="n">Figure</span><span class="p">,</span> <span class="n">pca_X</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">lc</span><span class="p">,</span> <span class="n">ln</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span> <span class="kc">False</span>    <span class="c1"># Ensure only one label for legend</span>
    <span class="k">for</span> <span class="n">coord</span><span class="p">,</span> <span class="n">label</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">pca_X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">c</span> <span class="o">=</span> <span class="s2">&quot;r&quot;</span> <span class="k">if</span> <span class="n">label</span> <span class="k">else</span> <span class="s2">&quot;#008FD5&quot;</span>
        <span class="n">m</span> <span class="o">=</span> <span class="s2">&quot;&lt;&quot;</span> <span class="k">if</span> <span class="n">label</span> <span class="k">else</span> <span class="s2">&quot;o&quot;</span>

        <span class="n">l</span> <span class="o">=</span> <span class="s2">&quot;Cancer&quot;</span> <span class="k">if</span> <span class="n">label</span> <span class="k">else</span> <span class="s2">&quot;Normal&quot;</span>
        <span class="k">if</span> <span class="n">l</span> <span class="o">==</span> <span class="s2">&quot;Cancer&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">lc</span><span class="p">:</span> <span class="n">lc</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">elif</span> <span class="n">l</span> <span class="o">==</span> <span class="s2">&quot;Normal&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">ln</span><span class="p">:</span> <span class="n">ln</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">else</span><span class="p">:</span> <span class="n">l</span> <span class="o">=</span> <span class="s2">&quot;_&quot;</span>
            
        <span class="n">ax</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">coord</span><span class="p">,</span> <span class="n">label</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">marker</span><span class="o">=</span><span class="n">m</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">l</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;PCA 1&quot;</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;probability of breast cancer&quot;</span><span class="p">)</span>


<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">4</span><span class="p">),</span> <span class="n">facecolor</span><span class="o">=</span><span class="s2">&quot;white&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="p">,</span> <span class="n">ax2</span> <span class="o">=</span> <span class="p">[</span><span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">)]</span>

<span class="n">linear_reg</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plot_data</span><span class="p">(</span><span class="n">ax1</span><span class="p">,</span> <span class="n">pca_X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">linear_reg</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Linear&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#E5AE42&quot;</span><span class="p">)</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax1</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s2">&quot;linear regression&quot;</span><span class="p">)</span>

<span class="n">logistic_reg</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
<span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">6</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
<span class="n">plot_data</span><span class="p">(</span><span class="n">ax2</span><span class="p">,</span> <span class="n">pca_X_test</span><span class="p">,</span> <span class="n">y_test</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">logistic_reg</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;Logistic&quot;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s2">&quot;#E5AE42&quot;</span><span class="p">)</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">ax2</span><span class="o">.</span><span class="n">title</span><span class="o">.</span><span class="n">set_text</span><span class="p">(</span><span class="s2">&quot;logsitic regression&quot;</span><span class="p">)</span>

<span class="n">fig</span><span class="o">.</span><span class="n">subplots_adjust</span><span class="p">(</span><span class="n">hspace</span><span class="o">=</span><span class="mf">0.25</span><span class="p">,</span> <span class="n">wspace</span><span class="o">=</span><span class="mf">0.40</span><span class="p">)</span>
<span class="n">fig</span><span class="o">.</span><span class="n">canvas</span><span class="o">.</span><span class="n">draw</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="figure align-center" id="lr-logreg-fig">
<div class="cell_output docutils container">
<img alt="../_images/3_statistical_inference_69_0.png" src="../_images/3_statistical_inference_69_0.png" />
</div>
<p class="caption"><span class="caption-number">Fig. 4.14 </span><span class="caption-text">Linear and Logistic Regression on breast cancer PCA 1 test set.</span><a class="headerlink" href="#lr-logreg-fig" title="Permalink to this image">¶</a></p>
</div>
<p>As we can observe from the results, the Logistic Regression is better suited to classification than the Linear one. They respectively yield an <span class="math notranslate nohighlight">\(82.98\)</span>% accuracy on the test set for the logistic regression, against <span class="math notranslate nohighlight">\(70.21\)</span>% for the linear regression.</p>
<p>It is possible to verify the assumption that one model is better than another one by applying our knowledge on hypothesis testing. However, this will not be treated in this chapter.</p>
</div>
<div class="section" id="naive-bayes-classification">
<h3><span class="section-number">4.6.2. </span>Naive Bayes Classification<a class="headerlink" href="#naive-bayes-classification" title="Permalink to this headline">¶</a></h3>
</div>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./2_applied_mathematics"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="2_probabilities_and_information_theory.html" title="previous page"><span class="section-number">3. </span>Probabilities and Information Theory</a>
    <a class='right-next' id="next-link" href="../3_machine_learning/0_introduction.html" title="next page"><span class="section-number">1. </span>Introduction</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Yliess HATI<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>